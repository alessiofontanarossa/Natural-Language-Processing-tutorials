{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95dbfb0d",
   "metadata": {},
   "source": [
    "As it is (without anything downloaded and always with 1 epoch when needed), the running time of the whole notebook is (approximately) <span style=\"background-color: lightblue\"> 4 minutes</span>.\n",
    "\n",
    "<span style=\"background-color: yellow\"> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab0bca2",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "446fdb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## UTILITY AND SYSTEM ##########################\n",
    "\n",
    "import os                       # filesystem operations\n",
    "import csv                      # reading/writing CSV files\n",
    "import json                     # JSON parsing and serialization\n",
    "import math                     # basic math functions\n",
    "import random                   # random number generation\n",
    "import time                     # time-related functions\n",
    "import tempfile                 # temporary file management\n",
    "import tarfile                  # tar archive handling\n",
    "import io                       # input/output streams\n",
    "import pickle                   # object serialization\n",
    "import importlib                # dynamic import of modules\n",
    "import multiprocessing          # parallel process management\n",
    "import pkg_resources            # package and dependency management\n",
    "from copy import deepcopy       # deep copy of objects\n",
    "from pathlib import Path        # filesystem paths handling (cross-platform)\n",
    "\n",
    "########################## DOWNLOAD ##########################\n",
    "\n",
    "import requests                 # HTTP requests library\n",
    "import wget                     # file downloads from URLs\n",
    "from urllib.request import urlopen  # open URLs (alternative to requests)\n",
    "\n",
    "########################## VISUALIZATION ##########################\n",
    "\n",
    "import matplotlib.pyplot as plt # basic plotting library\n",
    "import plotly.graph_objs as go  # interactive plotting\n",
    "from tqdm.notebook import tqdm  # progress bars for loops in notebooks\n",
    "from pprint import pprint       # formatted pretty-printing of objects\n",
    "\n",
    "########################## DATAFRAME ##########################\n",
    "\n",
    "import numpy as np              # numerical arrays and operations\n",
    "import pandas as pd             # dataframes and data manipulation\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "########################## TEXT PROCESSING ##########################\n",
    "\n",
    "import re                      # regular expressions\n",
    "import string                  # string constants and operations\n",
    "from itertools import chain, islice  # advanced iteration and chaining\n",
    "\n",
    "########################## TOKENIZATION ##########################\n",
    "\n",
    "from collections import Counter, OrderedDict  # frequency counts and ordered dictionaries\n",
    "import nltk                                   # natural language processing toolkit\n",
    "from nltk.tokenize import word_tokenize       # word tokenization\n",
    "import spacy                                  # advanced NLP (tokenization, parsing)\n",
    "from torchtext.data.utils import get_tokenizer       # torchtext tokenizers\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator # build vocabulary from iterator\n",
    "\n",
    "########################## DATASET AND DATALOADER ##########################\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split   # datasets and data loading utilities\n",
    "from torch.nn.utils.rnn import pad_sequence                      # padding variable-length sequences\n",
    "from datasets import load_dataset, DatasetDict                   # HuggingFace datasets loading\n",
    "from torchtext.datasets import AG_NEWS                           # torchtext built-in datasets\n",
    "\n",
    "########################## PYTORCH AND DEEP LEARNING ##########################\n",
    "\n",
    "import torch                             # PyTorch main library\n",
    "from torch import nn, Tensor             # neural network modules and tensors\n",
    "from torch.nn import CrossEntropyLoss    # common loss function for classification\n",
    "from torchsummary import summary as torchsummary\n",
    "from torchinfo import summary as torchinfosummary\n",
    "\n",
    "########################## WORD EMBEDDING ##########################\n",
    "\n",
    "from torchtext.vocab import GloVe        # pretrained GloVe embeddings\n",
    "# from gensim.models import Word2Vec     # word2vec embeddings from corpus (commented out)\n",
    "\n",
    "########################## HUGGING FACE ##########################\n",
    "\n",
    "import transformers                      # transformers library core\n",
    "from transformers import (\n",
    "    GPT2Tokenizer, GPT2LMHeadModel,     # GPT-2 tokenizer and model\n",
    "    BertTokenizer, BertTokenizerFast, BertConfig, BertForMaskedLM,  # BERT components\n",
    "    XLNetTokenizer,                     # XLNet tokenizer\n",
    "    DistilBertForSequenceClassification, DistilBertTokenizer, AutoModelForSequenceClassification,\n",
    "    pipeline,                          # easy pipelines for inference\n",
    "    AutoTokenizer,                    # auto tokenizer loader\n",
    "    AutoModelForCausalLM, GPT2ForSequenceClassification,\n",
    "    DataCollatorForLanguageModeling, TrainingArguments, Trainer,  # training utilities\n",
    "    set_seed, GenerationConfig,\n",
    "    BertModel,                        # BERT base model\n",
    "    PreTrainedTokenizerBase\n",
    ")\n",
    "from datasets import DatasetDict         # HuggingFace dataset dictionaries\n",
    "\n",
    "######################### TRL & PEFT (TRAINING & PARAMETER EFFICIENT FINE-TUNING) ##########################\n",
    "\n",
    "from trl import (\n",
    "    SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM,\n",
    "    DPOConfig, DPOTrainer,\n",
    "    RewardTrainer, RewardConfig\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from torchmetrics import Accuracy        # metrics for evaluation\n",
    "\n",
    "########################## RAG ##########################\n",
    "\n",
    "from transformers import (\n",
    "    DPRQuestionEncoder, DPRQuestionEncoderTokenizer,\n",
    "    DPRContextEncoder, DPRContextEncoderTokenizer\n",
    ")\n",
    "import faiss                              # similarity search library\n",
    "\n",
    "########################## EVALUATION ##########################\n",
    "\n",
    "import evaluate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "792e3d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which device we are on: cpu\n"
     ]
    }
   ],
   "source": [
    "def accelerator(where = \"mps\"):\n",
    "    if where == \"mps\":\n",
    "        device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        print(\"Which device we are on: {}\".format(device))\n",
    "        return device\n",
    "    if where == \"cuda\":\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"Which device we are on: {}\".format(device))\n",
    "        return device\n",
    "    if where == \"cpu\":\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Which device we are on: {}\".format(device))\n",
    "        return device\n",
    "\n",
    "device = accelerator(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f59e9",
   "metadata": {},
   "source": [
    "# A) CONCEPTS: Instruction-Tuning, Reward modelling, PPO, DPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1ad6c9",
   "metadata": {},
   "source": [
    "## Fine-Tuning vs Alignement-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3929b64",
   "metadata": {},
   "source": [
    "Fine-tuning LLMs adapts pre-trained models to specif tasks/domains using domain-specific data. This process adjust model's parameters to improve task performance, and is useful if you have a limited dataset. Moreover it is time and resources efficient. We should pay attention to **catastrophic forgetting**, to prevent the model from losing its initial broad knowledge. Two main approaches to optimize language models:\n",
    "1. <span style=\"background-color: yellow\">FINE-TUNING</span>: improve the general features of a model on a specific task, or <span style=\"background-color: pink\">\"learn the task\"</span>. This can be done in various ways:\n",
    "    1. Self-supervised fine-tuning;\n",
    "    2. SFT supervised fine-tuning:\n",
    "        - Full fine-tuning;\n",
    "        - PEFT Parameter-efficient fine-tuning (<span style=\"background-color: orange\">adapters and LoRA</span>);\n",
    "2. <span style=\"background-color: yellow\">ALIGNEMENT-TUNING</span>: improve the behaviour and alignement of a model on the human preferences, or <span style=\"background-color: pink\">\"become similar to humans\"</span>. This is done with:\n",
    "    - Instruction-tuning, which is supervised, and then (one or the other):\n",
    "        1. RHLF: reinforcement learning from human feedback, or reward-modelling;\n",
    "        2. DPO: direct preference optimization, which does not need rewards and is directly controlled by humans.\n",
    "\n",
    "| Aspect                         | <span style=\"background-color: yellow\">FINE-TUNING</span>              | <span style=\"background-color: yellow\">ALIGNEMENT-TUNING</span>  |\n",
    "|-------------------------------|--------------------------------------------------|---------------------------------------------------|\n",
    "| **Main Goal**                 | Task-specific skill improvement                  | Align model behavior with human intent            |\n",
    "| **Data Format**              | Input → Target (e.g., text → label or answer)    | Instruction + Response, Human Preference pairs    |\n",
    "| **Supervision Type**         | Supervised or semi-supervised                    | Supervised (instructions), Reinforcement (RLHF), or Preference Optimization (DPO) |\n",
    "| **Use Case**                 | Classification, summarization, translation, etc. | Chatbots, assistants, safe and helpful responses  |\n",
    "| **Model Focus**              | Learning the correct output                      | Learning *how to behave* appropriately            |\n",
    "| **Parameter Updates**        | Full model (or partial via PEFT)                 | Usually full model tuning in multiple stages      |\n",
    "| **Typical Final Goal**       | Accuracy, F1, BLEU, etc.                         | Helpfulness, safety, alignment with human values  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab49f998",
   "metadata": {},
   "source": [
    "## Alignement-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d7af39",
   "metadata": {},
   "source": [
    "### Instruction-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a655cd1",
   "metadata": {},
   "source": [
    "It trains the model with <span style=\"background-color: yellow\">expert labeled dataset </span> and is used before DPO (direct preference optimization) and RLHF (Reinf Learning from human feedback). It is composed by:\n",
    "1. **instruction** (es: answer the following question based on the provided context)\n",
    "2. **input** (es: What is the most important achievement of Einstein? He was a physicist.) **Not all models have input**\n",
    "3. **output** (es: He is best known for E=mc^2.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4fba8a",
   "metadata": {},
   "source": [
    "Usually, we use **Instruction masking**:\n",
    "\n",
    "During training, instruction tokens are masked (ignored in loss calculation), while response tokens are unmasked (used to compute loss).\n",
    "This ensures the model focuses on learning how to generate accurate answers rather than memorizing question formats.\n",
    "\n",
    "Why?\n",
    "\n",
    "Prevents overfitting to the instruction phrasing\n",
    "\n",
    "Improves response generation quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443d4d94",
   "metadata": {},
   "source": [
    "The temperature parameter in language models controls how random or predictable the generated responses are. Here's a simple breakdown:\n",
    "\n",
    "Low Temperature (e.g., 0.5): The model becomes more conservative. It tends to choose words that are more likely based on the context, leading to more predictable and coherent responses. Think of it as a chef sticking to a traditional recipe.\n",
    "High Temperature (e.g., 2.0 or higher): The model becomes more adventurous. It allows for a wider range of word choices, including less likely options, resulting in more diverse and creative responses. This is like a chef experimenting with unusual ingredients.\n",
    "\n",
    "Example: \n",
    "\n",
    "At a low temperature, if the prompt is \"The sky is,\" the model might generate \"blue\" or \"clear.\"\n",
    "At a high temperature, it might generate \"purple\" or \"filled with marshmallows,\" leading to more unexpected and imaginative responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7473266",
   "metadata": {},
   "source": [
    "#### examples of templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ae5080",
   "metadata": {},
   "source": [
    "Let's review certain examples for various templates:\n",
    "\n",
    "---\n",
    "#### Response template\n",
    "Template: `### Question: {question}\\n ### Answer: {answer}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Question: What is the capital of France?\n",
    "### Answer: Paris\n",
    "```\n",
    "\n",
    "---\n",
    "#### Conversation template\n",
    "\n",
    "Template: `### User: {user_input}\\n ### Bot: {bot_response}`\n",
    "Example:\n",
    "```\n",
    "### User: How are you today?\n",
    "### Bot: I'm doing great, thank you! How can I assist you today?\n",
    "```\n",
    "\n",
    "---\n",
    "#### Instruction and output template\n",
    "\n",
    "Template: `### Instruction: {instruction}\\n ### Output: {output}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Instruction: Translate the following sentence to Spanish: \"Hello, how are you?\"\n",
    "### Output: \"Hola, ¿cómo estás?\"\n",
    "```\n",
    "\n",
    "---\n",
    "#### Completion template\n",
    "\n",
    "Template: `{prompt} ### Completion: {completion}`\n",
    "Example:\n",
    "```\n",
    "Once upon a time in a faraway land, ### Completion: there lived a wise old owl who knew all the secrets of the forest.\n",
    "```\n",
    "\n",
    "#### Summarization template\n",
    "\n",
    "Template: `### Text: {text}\\n ### Summary: {summary}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Text: The quick brown fox jumps over the lazy dog.\n",
    "### Summary: A fox jumps over a dog.\n",
    "```\n",
    "\n",
    "---\n",
    "#### Dialogue template\n",
    "\n",
    "Template: `### Speaker 1: {utterance_1}\\n ### Speaker 2: {utterance_2}\\n ### Speaker 1: {utterance_3}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Speaker 1: Hi, what are you doing today?\n",
    "### Speaker 2: I'm going to the park.\n",
    "### Speaker 1: That sounds fun!\n",
    "```\n",
    "\n",
    "---\n",
    "#### Code generation template\n",
    "\n",
    "Template: `### Task: {task_description}\\n ### Code: {code_output}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Task: Write a function to add two numbers in Python.\n",
    "### Code: def add(a, b):\\n    return a + b\n",
    "```\n",
    "\n",
    "---\n",
    "#### Data analysis template\n",
    "\n",
    "Template: `### Analysis Task: {task_description}\\n ### Analysis: {analysis_output}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Analysis Task: Provide insights from the sales data of Q1 2022.\n",
    "### Analysis: The sales increased by 15% compared to Q4 2021, with the highest growth in the electronics category.\n",
    "```\n",
    "\n",
    "---\n",
    "#### Recipe template\n",
    "\n",
    "Template: `### Recipe Name: {recipe_name}\\n ### Ingredients: {ingredients}\\n ### Instructions: {instructions}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Recipe Name: Chocolate Chip Cookies\n",
    "### Ingredients: Flour, Sugar, Chocolate Chips, Butter, Eggs, Vanilla Extract\n",
    "### Instructions: Mix the dry ingredients, add the wet ingredients, fold in the chocolate chips, and bake at 350°F for 10-12 minutes.\n",
    "```\n",
    "\n",
    "---\n",
    "#### Explanation template\n",
    "\n",
    "Template: `### Concept: {concept}\\n ### Explanation: {explanation}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Concept: Photosynthesis\n",
    "### Explanation: Photosynthesis is the process by which green plants use sunlight to synthesize nutrients from carbon dioxide and water.\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096cd1d8",
   "metadata": {},
   "source": [
    "### RLHF: Reward modelling (Response Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5296a1",
   "metadata": {},
   "source": [
    "Quantify response quality by assigning numerical values to responses to assess and compare performances. Moreover it reflects user preferences for customized model behaviour:\n",
    "\n",
    "- The dataset used in this case, as said in 'instruction-tuning' is an <span style=\"background-color: yellow\">expert labeled dataset </span>. In particular, given a model, it comprises:\n",
    "    - a question;\n",
    "    - one or more answers predicted by the model;\n",
    "    - a label, given by an human, which choose the preferable answer.\n",
    "\n",
    "For example\n",
    "\n",
    "| Prompt                                                | Response A                                           | Response B                                           | Preferred |\n",
    "|-------------------------------------------------------|------------------------------------------------------|------------------------------------------------------|-----------|\n",
    "| What is the capital of France?                        | The capital of France is Paris.                      | France is a country in Europe.                       | A         |\n",
    "| Can you explain the theory of evolution in simple terms? | Evolution is the idea that species change over time through natural selection. | Charles Darwin was a British naturalist born in 1809. | A         |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " We tokenize the query (with tokens $\\text{word}_{i}$) and the answer (with tokens $\\widehat{\\text{word}}_{i}$, where the hat is present because this is generated by the model, so it is an extimation). Then we use the function $r$ on \n",
    "\n",
    "$$ r(\\text{word}_1,\\ldots,\\text{word}_{N_{\\text{query}}},\\widehat{\\text{word}}_1,\\ldots,\\widehat{\\text{word}}_{N_{\\text{answer}}})\\,.$$\n",
    "\n",
    "This function $r$ is obtained with a trainable model with an appropriate loss. So we want to train a model that identifies the desidered model from another model, basing on context and preferences.\n",
    "1. **function $r$**: it is the contextual embedding from an encoder of the concatenated $\\text{word}_1,\\ldots,\\text{word}_{N_{\\text{query}}},\\widehat{\\text{word}}_1,\\ldots,\\widehat{\\text{word}}_{N_{\\text{answer}}}$. This embedding is then projected (e.g., via a linear layer) to a scalar reward score.\n",
    "2. **Bradley-Terry reward loss** is used: using two different responses $A$ and $B$, find the parameters by applying \n",
    "\n",
    "$$ \\argmin_{\\text{parameters}} \\bigl[-\\sigma(r_A - r_B) \\bigr]\\,.$$  \n",
    "This encourages the model to assign a higher score to the preferred response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63e2633",
   "metadata": {},
   "source": [
    "Given a reward function $r$, the expected reward for N queries, each with K possible answers, is\n",
    "\n",
    "$$ E[r]\\sim \\frac{1}{N}\\sum_{n}^{N} \\frac{1}{K} \\sum_{k}^{K} r(\\text{query}_n, \\text{answer}_{n,k})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bab81a",
   "metadata": {},
   "source": [
    "### Proximal Policy Optimization (PPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f411d",
   "metadata": {},
   "source": [
    "The idea is to use reinforcement learning (from human feedback) like this:\n",
    "1. We have a LLM model $M_L$ (that needs to be fine-tuned by instruction fine-tuning), a reference model $M$ (pre-trained) and a reward model $M_R$;\n",
    "2. Give a $\\text{query}_n$ to $M_L$, this produces $K$ answers $\\text{answer}_{n,k}$;\n",
    "3. The model $M_R$ computes the rewards $r(\\text{query}_n, \\text{answer}_{n,k})$;\n",
    "4. Maximize a target function, which is the PPO (Proximal Policy Optimization) objective:\n",
    "   - a) Compute the log-probabilities of the generated answers under the current and reference (pre-trained) models;\n",
    "   - b) Use the reward signal $r$ to calculate the advantage estimates (e.g., via Generalized Advantage Estimation - GAE);\n",
    "   - c) Optimize the PPO clipped objective to update $M_L$, encouraging responses with higher rewards while staying close to the reference model;\n",
    "   - d) Optionally apply KL penalties to prevent the model from drifting too far from the original distribution;\n",
    "   - e) Repeat this process across multiple queries, batches, and epochs until convergence or performance stabilizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fcbdb2",
   "metadata": {},
   "source": [
    "### Direct Preference Optimization (DPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aba278",
   "metadata": {},
   "source": [
    "Differently from the indirect $r$ method, DPO (which is a RL tecnique) directly change parameters to produce output aligned with human's feedback. In practice, the User should choose among two outputs. The optimal solution is to minimze the KL divergence, which brings to\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{DPO}} = -\\log\\bigg[ \\frac{\\exp(\\beta \\cdot \\log \\pi_\\theta(y^+|x))}{\\exp(\\beta \\cdot \\log \\pi_\\theta(y^+|x)) + \\exp(\\beta \\cdot \\log \\pi_\\theta(y^-|x))} \\bigg]\\,.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f67e3",
   "metadata": {},
   "source": [
    "# 1) Instruction-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c11485",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe70d56",
   "metadata": {},
   "source": [
    "We use the CodeAlpaca 20k dataset (a coding dataset), and to keep thing simple we discard the examples that contain any 'input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "16484d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(19888) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-08-03 16:21:22--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WzOT_CwDALWedTtXjwH7bA/CodeAlpaca-20k.json\n",
      "Risoluzione di cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 198.23.119.245\n",
      "Connessione a cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|198.23.119.245|:443... connesso.\n",
      "Richiesta HTTP inviata, in attesa di risposta... 200 OK\n",
      "Lunghezza: 6957007 (6.6M) [application/json]\n",
      "Salvataggio in: «CodeAlpaca-20k.json»\n",
      "\n",
      "CodeAlpaca-20k.json 100%[===================>]   6.63M  3.42MB/s    in 1.9s    \n",
      "\n",
      "2025-08-03 16:21:25 (3.42 MB/s) - «CodeAlpaca-20k.json» salvato [6957007/6957007]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WzOT_CwDALWedTtXjwH7bA/CodeAlpaca-20k.json\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files = \"CodeAlpaca-20k.json\", split = \"train\") #this *does not* take only the train subset\n",
    "dataset = dataset.filter(lambda example: example[\"input\"] == '')\n",
    "\n",
    "dataset = dataset.shuffle(seed=42) #shuffle it to be sure\n",
    "\n",
    "dataset_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = dataset_split['train']\n",
    "test_dataset = dataset_split['test']\n",
    "\n",
    "tiny_train_dataset = train_dataset.select(range(10))\n",
    "tiny_test_dataset = test_dataset.select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3be384c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'for i in list_str:\\n  print(i.upper())',\n",
       " 'instruction': 'Given the following list of strings:\\n\\nlist_str  = [\"one\", \"two\", \"three\", \"four\", \"five\"]\\n\\nWrite a program that prints out the strings in uppercase.',\n",
       " 'input': ''}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_train_dataset[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b2fc51",
   "metadata": {},
   "source": [
    "## Model to be fine-tuned on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f152539",
   "metadata": {},
   "source": [
    "We load the model and its own toeknizer. This is not fine-tuned for prompt structured as \"### Instruction:\" and \"### Response:\". We will have to take this into account later, in the pre-processing section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f0748a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\", padding_side = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b610b",
   "metadata": {},
   "source": [
    "## Pre-processing of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8903a82f",
   "metadata": {},
   "source": [
    "It is necessary now to put the dataset in a suitable format. The suitable format, in this case, is\n",
    "```\n",
    "'### Instruction:\\nConstruct an array of size 10 to store integers in Java.\\n\\n### Response:\\nint[] array = new int[10];</s>'\n",
    "```\n",
    "Here `</s>` is the end toke, available as `tokenizer.eos_token`.\n",
    "\n",
    "In particular we need to generate two functions, one with instructions and responses, and one with the instructions only for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da05bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(dataset):\n",
    "    output_texts = []\n",
    "    for i in range(len(dataset['instruction'])):\n",
    "        text = (\n",
    "            f\"### Instruction:\\n{dataset['instruction'][i]}\"\n",
    "            f\"\\n\\n### Response:\\n{dataset['output'][i]}</s>\"\n",
    "        )\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "def formatting_prompts_func_no_response(dataset):\n",
    "    output_texts = []\n",
    "    for i in range(len(dataset['instruction'])):\n",
    "        text = f\"### Instruction:\\n{dataset['instruction'][i]}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b5e3d2",
   "metadata": {},
   "source": [
    "Example of usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a667afd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "How do you remove the last item from a list in Python?\n",
      "\n",
      "### Response:\n",
      "list.pop()</s>\n"
     ]
    }
   ],
   "source": [
    "print(formatting_prompts_func(tiny_test_dataset)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0784935",
   "metadata": {},
   "source": [
    "On the test dataset, we have to create some lists\n",
    "\n",
    "| List                         | Content                                                           | Purpose                                                                 |\n",
    "|-----------------------------|--------------------------------------------------------------------|-------------------------------------------------------------------------|\n",
    "| `instructions_with_responses` | Full prompt: **instruction + expected response + `</s>` token**     | Create `expected_outputs`                  |\n",
    "| `instructions`                | Only **instruction**, without response                             | Used as input to test the model (to generate the response)              |\n",
    "| `expected_outputs`            | Only **expected response**, extracted from `instructions_with_responses`, without `</s>`  | Used to compare with generated output and compute metrics (e.g., BLEU) |\n",
    "\n",
    "\n",
    "Moreover, we could not have created them before (in particular the outputs) because:\n",
    "\n",
    "| Aspect                | `dataset[\"output\"]`                            | `expected_outputs`                                                  |\n",
    "|-----------------------|------------------------------------------------|----------------------------------------------------------------------|\n",
    "| Source                | Directly from the original dataset             | Extracted from tokenized prompt and response                        |\n",
    "| Includes `</s>`       | May include `</s>` if present in the dataset   | Explicitly removes `</s>` during processing                         |\n",
    "| Based on tokenization | ❌ Not tokenized                               | ✅ Tokenized and decoded from model input                            |\n",
    "| Used for BLEU/metrics | ❌ Not reliable for precise metrics            | ✅ Used for exact match and evaluation (e.g., BLEU, SacreBLEU)       |\n",
    "| Alignment with model  | Might not match token-level model outputs      | Precisely aligned with model-generated tokens                       |\n",
    "| Purpose               | For general inspection or display              | For rigorous evaluation of model's response                         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "03dc1c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08477f341864489fb648c98a41e2b085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1953 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# it takes 36s\n",
    "\n",
    "expected_outputs = []\n",
    "instructions_with_responses = formatting_prompts_func(test_dataset)\n",
    "instructions = formatting_prompts_func_no_response(test_dataset)\n",
    "for i in tqdm(range(len(instructions_with_responses))):\n",
    "    tokenized_instruction_with_response = tokenizer(instructions_with_responses[i], return_tensors=\"pt\", max_length=1024, truncation=True, padding=False)\n",
    "    tokenized_instruction = tokenizer(instructions[i], return_tensors=\"pt\", max_length=1024, truncation=True, padding=False)\n",
    "    expected_output = tokenizer.decode(\n",
    "    tokenized_instruction_with_response['input_ids'][0][len(tokenized_instruction['input_ids'][0]):],\n",
    "    skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    expected_outputs.append(expected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bb255d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## \"INSTRUCTIONS\" LIST: ##############\n",
      "### Instruction:\n",
      "How do you remove the last item from a list in Python?\n",
      "############## \"INSTRUCTIONS_WITH_RESPONSES\" LIST ##############\n",
      "### Instruction:\n",
      "How do you remove the last item from a list in Python?\n",
      "\n",
      "### Response:\n",
      "list.pop()</s>\n",
      "\n",
      "############## \"EXPECTED_OUTPUTS\" LIST: ##############\n",
      "\n",
      "### Response:\n",
      "list.pop()\n"
     ]
    }
   ],
   "source": [
    "print('############## \"INSTRUCTIONS\" LIST: ##############\\n' + instructions[2])\n",
    "print('############## \"INSTRUCTIONS_WITH_RESPONSES\" LIST ##############\\n' + instructions_with_responses[2])\n",
    "print('\\n############## \"EXPECTED_OUTPUTS\" LIST: ##############' + expected_outputs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "674a5391",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListDataset(Dataset):\n",
    "    def __init__(self, original_list):\n",
    "        self.original_list = original_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.original_list)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.original_list[i]\n",
    "\n",
    "instructions_torch = ListDataset(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316efb6c",
   "metadata": {},
   "source": [
    "## Test the model without fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8dd0e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_pipeline = pipeline(\"text-generation\",\n",
    "                        model = model,\n",
    "                        tokenizer = tokenizer,\n",
    "                        device = device,\n",
    "                        batch_size = 2,\n",
    "                        max_length = 50, #this limit the generated tokens for prompt+output (which may not be always right)\n",
    "                        max_new_tokens = 50, # This limit only the generated tokens\n",
    "                        return_full_text = False) #if True, the generation pipeline generates both the instructions and the responses\n",
    "                        # return_tensors = True) #if True, the generation pipeline returns token IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "025c71f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=50) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=50) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "# it takes 40s\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Due to resource limitation, only apply the function on 3 records using \"instructions_torch[:10]\"\n",
    "    pipeline_iterator= gen_pipeline(instructions[:3], \n",
    "                                    max_length = 50, # this is set to 50 due to resource constraint, using a GPU, you can increase it to the length of your choice\n",
    "                                    num_beams = 5,\n",
    "                                    early_stopping = True)\n",
    "\n",
    "generated_outputs_base = []\n",
    "for i, text in enumerate(pipeline_iterator):\n",
    "    gen_output = text[0][\"generated_text\"]\n",
    "    prompt = instructions[i]\n",
    "    response_only = gen_output[len(prompt):].strip()\n",
    "    generated_outputs_base.append(response_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "533781f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 1: \n",
      "### Instruction:\n",
      "Name the most important benefit of using a database system.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 1: \n",
      "\n",
      "\n",
      "### Response:\n",
      "The most important benefit of using a database system is the ability to store and retrieve data quickly and easily. Database systems also provide support for data security, data integrity, and concurrently accessing and modifying data from multiple systems.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 1: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 2: \n",
      "### Instruction:\n",
      "Come up with a Java program that checks if one string is a substring of another.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 2: \n",
      "\n",
      "\n",
      "### Response:\n",
      "public static boolean isSubstring(String s, String x) {\n",
      "    int i = 0, j = 0;\n",
      "    while (i < s.length() && j < x.length()) {\n",
      "        if (s.charAt(i) == x.charAt(j)) {\n",
      "            i++;\n",
      "            j++;\n",
      "        } else {\n",
      "            i = i - j + 1;\n",
      "            j = 0;\n",
      "        }\n",
      "    }\n",
      "    if (j == x.length()) {\n",
      "        return true;\n",
      "    }\n",
      "    return false;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 2: \n",
      "the string is not a substring of another string, it is not a substring of another string. If the string is not a\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 3: \n",
      "### Instruction:\n",
      "How do you remove the last item from a list in Python?\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 3: \n",
      "\n",
      "\n",
      "### Response:\n",
      "list.pop()\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 3: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('@@@@@@@@@@@@@@@@@@@@')\n",
    "    print('@@@@@ Instruction '+ str(i+1) +': ')\n",
    "    print(instructions[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@ Expected response '+ str(i+1) +': ')\n",
    "    print(expected_outputs[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@ Generated response '+ str(i+1) +': ')\n",
    "    print(generated_outputs_base[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@@@@@@@@@@@@@@@@')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a467eb54",
   "metadata": {},
   "source": [
    "Let's set up a metric that compares the generated responses and the expected responses in the test environment. In this lab, let's use the [BLEU score](https://en.wikipedia.org/wiki/BLEU), a metric originally intended to check the quality of translations made by translation models. You can calculate the BLEU scores for individual generated segments by comparing them with a set of expected outputs and average the scores for the individual segments. Depending on the implementation, BLEU scores range from 0 to 1 or from 0 to 100 (as in the implementation used herein), with higher scores indicating a better match between the model generated output and the expected output.\n",
    "\n",
    "_**Note:**_ \n",
    "1. The BLEU score was originally implemented for assessing the quality of translations. However, it may not necessarily be the best metric for instruction fine-tuning in general, but it is nonetheless a useful metric that gives a sense of the alignment between the model generated output and the expected output.\n",
    "2. BLEU scores are very challenging to compare from one study to the next because it is a parametrized metric. As a result, you can employ a variant of BLEU called [SacreBLEU](https://aclanthology.org/W18-6319/) invariant to the metric's parametrization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "672a93f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "results_base = sacrebleu.compute(predictions = generated_outputs_base,\n",
    "                                 references = expected_outputs[0:3])\n",
    "\n",
    "print(list(results_base.keys()))\n",
    "print(round(results_base[\"score\"], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7fb5c5",
   "metadata": {},
   "source": [
    "### Loading complete data (not really needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a4dcf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/VvQRrSqS1P0_GobqtL-SKA/instruction-tuning-generated-outputs-base.pkl')\n",
    "generated_outputs_base = pickle.load(io.BytesIO(urlopened.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3d4d9fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 1: \n",
      "### Instruction:\n",
      "Name the most important benefit of using a database system.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 1: \n",
      "\n",
      "\n",
      "### Response:\n",
      "The most important benefit of using a database system is the ability to store and retrieve data quickly and easily. Database systems also provide support for data security, data integrity, and concurrently accessing and modifying data from multiple systems.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 1: \n",
      "Thank you for your question.\n",
      "\n",
      "### Response:\n",
      "Thank you for your question.\n",
      "\n",
      "### Response:\n",
      "Thank you for your question.\n",
      "\n",
      "### Response:\n",
      "Thank you for your question.\n",
      "\n",
      "### Response:\n",
      "Thank you for your question.\n",
      "\n",
      "### Response:\n",
      "Thank you for your question.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 2: \n",
      "### Instruction:\n",
      "Come up with a Java program that checks if one string is a substring of another.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 2: \n",
      "\n",
      "\n",
      "### Response:\n",
      "public static boolean isSubstring(String s, String x) {\n",
      "    int i = 0, j = 0;\n",
      "    while (i < s.length() && j < x.length()) {\n",
      "        if (s.charAt(i) == x.charAt(j)) {\n",
      "            i++;\n",
      "            j++;\n",
      "        } else {\n",
      "            i = i - j + 1;\n",
      "            j = 0;\n",
      "        }\n",
      "    }\n",
      "    if (j == x.length()) {\n",
      "        return true;\n",
      "    }\n",
      "    return false;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 2: \n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 3: \n",
      "### Instruction:\n",
      "How do you remove the last item from a list in Python?\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 3: \n",
      "\n",
      "\n",
      "### Response:\n",
      "list.pop()\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 3: \n",
      "The CSS rule is set to “big-header”.\n",
      "\n",
      "### Response:\n",
      "The CSS rule is set to “big-header”.\n",
      "\n",
      "### Response:\n",
      "The CSS rule is set to “big-header”.\n",
      "\n",
      "### Response:\n",
      "The CSS rule is set to “big-header”.\n",
      "\n",
      "### Response:\n",
      "The CSS rule is set to “big-header”.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('@@@@@@@@@@@@@@@@@@@@')\n",
    "    print('@@@@@ Instruction '+ str(i+1) +': ')\n",
    "    print(instructions[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@ Expected response '+ str(i+1) +': ')\n",
    "    print(expected_outputs[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@ Generated response '+ str(i+1) +': ')\n",
    "    print(generated_outputs_base[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@@@@@@@@@@@@@@@@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f17a274b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
      "1.4\n"
     ]
    }
   ],
   "source": [
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "results_base = sacrebleu.compute(predictions=generated_outputs_base,\n",
    "                                 references=expected_outputs)\n",
    "\n",
    "print(list(results_base.keys()))\n",
    "print(round(results_base[\"score\"], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b699f5f",
   "metadata": {},
   "source": [
    "## Train: Perform instruction fine-tuning with LoRA (Hugging Face)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de9d882",
   "metadata": {},
   "source": [
    "To save time, let's perform instruction fine-tuning using a parameter-efficient fine-tuning (PEFT) method called low-rank adaptation (LoRA). First, convert the model into a PEFT model suitable for LoRA fine-tuning by defining a `LoraConfig` object from the `peft library` that outlines LoRA parameters, such as the LoRA rank and the target modules. Next, apply LoRA configuration on the model using `get_peft_model()`, which effectively converts model into a LoRA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "70e8dfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r = 16,  # Low-rank dimension\n",
    "    lora_alpha = 32,  # Scaling factor\n",
    "    target_modules = [\"q_proj\", \"v_proj\"],  # Modules to apply LoRA\n",
    "    lora_dropout = 0.1,  # Dropout rate\n",
    "    task_type = TaskType.CAUSAL_LM  # Task type should be causal language model\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d3f3c",
   "metadata": {},
   "source": [
    "Instruction fine-tuning using the `SFTTrainer` has the effect of generating the instructions *and* the responses. However, for the purposes of assessing the quality of the generated text, consider only the quality of the response and not the quality of the instruction. For the purposes of calculating the BLEU score, eliminate the length of tokens corresponding to the instruction from the beginning of the tokenized model output. \n",
    "\n",
    "For example, suppose the tokenized instruction had a length of ten, but the generated text had a length of fourteen. Then the tokenized response that was kept for the purposes of calculating the BLEU score was just the four tokens at the end of the tokenized generated text because the first ten tokens represent the model's generation of the tokenized instruction.\n",
    "\n",
    "Although eliminating the first few tokens of the tokenized output worked well for the purposes of calculating BLEU. However, during fine-tuning, the first few tokens won't have an impact on the loss function. You can mask those tokens using -100 by ignoring the value of PyTorch loss functions such as [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html). By masking the tokens corresponding to the instruction with -100, only the tokens associated with the response can bear the loss.\n",
    "\n",
    "You can create such a masking manually by defining your own function. However, it is easier to instead use the `DataCollatorForCompletionOnlyLM` class from `trl`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6ff27c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_template = \"### Response:\\n\" #with this only the part after ### Response:\\n is read for the training\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2fd96026",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/tmp\",\n",
    "    num_train_epochs=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    #max_seq_length=1024,\n",
    "    do_eval=True,\n",
    "    fp16=False,   # forza esplicita\n",
    "    bf16=False,\n",
    "    no_cuda=True,  # forza uso CPU (MPS è considerato CPU-like)\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset,\n",
    "    formatting_func = formatting_prompts_func,\n",
    "    args = training_args,\n",
    "    # packing = False, #not accepted anymore\n",
    "    data_collator = collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7e79038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()\n",
    "# log_history_lora = trainer.state.log_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc553a86",
   "metadata": {},
   "source": [
    "## Test the fine-tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a463612",
   "metadata": {},
   "source": [
    "Same code as before, but it must be re-runned because the model has been converted to LoRA model, and also now it is (in principle) fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d99f6dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "# it takes 26s\n",
    "\n",
    "gen_pipeline = pipeline(\"text-generation\",\n",
    "                        model = model,\n",
    "                        tokenizer = tokenizer,\n",
    "                        device = device,\n",
    "                        batch_size = 2,\n",
    "                        max_length = 50,\n",
    "                        return_full_text = False)\n",
    "\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Due to resource limitation, only apply the function on 3 records using \"instructions_torch[:10]\"\n",
    "    pipeline_iterator = gen_pipeline(instructions[:3], \n",
    "                                    max_length = 50, # this is set to 50 due to resource constraint, using a GPU, you can increase it to the length of your choice\n",
    "                                    num_beams = 5,\n",
    "                                    early_stopping = True)\n",
    "\n",
    "generated_outputs_lora = []\n",
    "for i, text in enumerate(pipeline_iterator):\n",
    "    gen_output = text[0][\"generated_text\"]\n",
    "    prompt = instructions[i]\n",
    "    response_only = gen_output[len(prompt):].strip()\n",
    "    generated_outputs_lora.append(response_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d7c43637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 1: \n",
      "### Instruction:\n",
      "Name the most important benefit of using a database system.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 1: \n",
      "\n",
      "\n",
      "### Response:\n",
      "The most important benefit of using a database system is the ability to store and retrieve data quickly and easily. Database systems also provide support for data security, data integrity, and concurrently accessing and modifying data from multiple systems.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 1: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 2: \n",
      "### Instruction:\n",
      "Come up with a Java program that checks if one string is a substring of another.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 2: \n",
      "\n",
      "\n",
      "### Response:\n",
      "public static boolean isSubstring(String s, String x) {\n",
      "    int i = 0, j = 0;\n",
      "    while (i < s.length() && j < x.length()) {\n",
      "        if (s.charAt(i) == x.charAt(j)) {\n",
      "            i++;\n",
      "            j++;\n",
      "        } else {\n",
      "            i = i - j + 1;\n",
      "            j = 0;\n",
      "        }\n",
      "    }\n",
      "    if (j == x.length()) {\n",
      "        return true;\n",
      "    }\n",
      "    return false;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 2: \n",
      "ring of another string\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 3: \n",
      "### Instruction:\n",
      "How do you remove the last item from a list in Python?\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 3: \n",
      "\n",
      "\n",
      "### Response:\n",
      "list.pop()\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 3: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('@@@@@@@@@@@@@@@@@@@@')\n",
    "    print('@@@@@ Instruction '+ str(i+1) +': ')\n",
    "    print(instructions[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@ Expected response '+ str(i+1) +': ')\n",
    "    print(expected_outputs[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@ Generated response '+ str(i+1) +': ')\n",
    "    print(generated_outputs_lora[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@@@@@@@@@@@@@@@@')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d4ae3e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "results_lora = sacrebleu.compute(predictions = generated_outputs_lora,\n",
    "                                 references = expected_outputs[0:3])\n",
    "print(list(results_lora.keys()))\n",
    "print(round(results_lora[\"score\"], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03263c8",
   "metadata": {},
   "source": [
    "### Using loaded data (not really needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12d123bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/o7uYxe15xvX4CN-6Lr10iA/instruction-tuning-generated-outputs-lora.pkl')\n",
    "generated_outputs_lora = pickle.load(io.BytesIO(urlopened.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "43ba541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 1: \n",
      "### Instruction:\n",
      "Name the most important benefit of using a database system.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 1: \n",
      "\n",
      "\n",
      "### Response:\n",
      "The most important benefit of using a database system is the ability to store and retrieve data quickly and easily. Database systems also provide support for data security, data integrity, and concurrently accessing and modifying data from multiple systems.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 1: \n",
      "The type of data structure to use to store key-value pairs in a Python program would be a key-value pair.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 2: \n",
      "### Instruction:\n",
      "Come up with a Java program that checks if one string is a substring of another.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 2: \n",
      "\n",
      "\n",
      "### Response:\n",
      "public static boolean isSubstring(String s, String x) {\n",
      "    int i = 0, j = 0;\n",
      "    while (i < s.length() && j < x.length()) {\n",
      "        if (s.charAt(i) == x.charAt(j)) {\n",
      "            i++;\n",
      "            j++;\n",
      "        } else {\n",
      "            i = i - j + 1;\n",
      "            j = 0;\n",
      "        }\n",
      "    }\n",
      "    if (j == x.length()) {\n",
      "        return true;\n",
      "    }\n",
      "    return false;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 2: \n",
      "\n",
      "A method to solve an equation of the form ax + b = 0 is:\n",
      "\n",
      "def solve(x, y):\n",
      "    return x * y\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 3: \n",
      "### Instruction:\n",
      "How do you remove the last item from a list in Python?\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 3: \n",
      "\n",
      "\n",
      "### Response:\n",
      "list.pop()\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 3: \n",
      ".big-header {\n",
      "    text-size: 24px;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('@@@@@@@@@@@@@@@@@@@@')\n",
    "    print('@@@@@ Instruction '+ str(i+1) +': ')\n",
    "    print(instructions[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@ Expected response '+ str(i+1) +': ')\n",
    "    print(expected_outputs[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@ Generated response '+ str(i+1) +': ')\n",
    "    print(generated_outputs_lora[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@@@@@@@@@@@@@@@@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c20a1259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
      "1.1\n"
     ]
    }
   ],
   "source": [
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "results_lora = sacrebleu.compute(predictions=generated_outputs_lora,\n",
    "                                 references=expected_outputs)\n",
    "print(list(results_lora.keys()))\n",
    "print(round(results_lora[\"score\"], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a13554",
   "metadata": {},
   "source": [
    "# 2) Reward Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "380a4555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(data, file_path):\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "    print(f\"Data successfully saved to {file_path}\")\n",
    "     \n",
    "def load_from_json(file_path):\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c6a26b",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb8c89c",
   "metadata": {},
   "source": [
    "In this section, you load a data set that is used for training the reward model. In this lab, you use the **Dahoas/synthetic-instruct-gptj-pairwise** data set from Hugging Face, a synthetic data set that is designed for training and evaluating instruction-following models. This data set includes pairs of prompts and responses, where one response is preferred over the other. The primary use case is to train models to distinguish between better and worse responses, essential for tasks like reinforcement learning with human feedback (RLHF).\n",
    "\n",
    "```Prompt:``` A text prompt that the model should respond to\n",
    "\n",
    "```Chosen:``` The preferred response to the prompt\n",
    "\n",
    "```Rejected:``` The less preferred response to the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cb9f8442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected'],\n",
      "        num_rows: 33143\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"Dahoas/synthetic-instruct-gptj-pairwise\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a3eda5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT----> How do I know if this is a good investment. \n",
      "\n",
      "CHOSEN----> Answer: To determine if an investment is a good one, it is important to consider the potential risks and rewards of the investment, as well as the cost, expected rate of return, and timeline involved in the investment. Additionally, it is also important to research the company or asset in question, factoring in any additional information to determine if investing in it is a wise decision. \n",
      "\n",
      "REJECTED----> It really depends on the details of your situation, and the kind of investor you are.  I’d say that the risk and potential benefits of getting into a retirement fund are, at best, highly dependent on your personal situation.  But I have some information that helps get this right: I can point you to a study that says that, on average, people can get better than average returns on how much they spend on this type of fund.  The risks of this fund are estimated to be. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "\n",
    "print('PROMPT---->', dataset[\"train\"][i]['prompt'],'\\n')\n",
    "    \n",
    "print('CHOSEN---->', dataset[ 'train'][i]['chosen'],'\\n')\n",
    "\n",
    "print('REJECTED---->', dataset[ 'train'][i]['rejected'],'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917261bb",
   "metadata": {},
   "source": [
    "## Model to be fine-tuned and tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126c9a85",
   "metadata": {},
   "source": [
    "It is important to set the `num_labels = 1` which is the r-score of the reward modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e544d39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", use_fast=True)\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels = 1)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "max_length = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8d820",
   "metadata": {},
   "source": [
    "## Pre-processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229b012d",
   "metadata": {},
   "source": [
    "We want to set question-answer in the format human-assistant, a typical format for gtp-like model (as this one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "473ce78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Human: How do I know if this is a good investment.\n",
      "\n",
      "Assistant: Answer: To determine if an investment is a good one, it is important to consider the potential risks and rewards of the investment, as well as the cost, expected rate of return, and timeline involved in the investment. Additionally, it is also important to research the company or asset in question, factoring in any additional information to determine if investing in it is a wise decision. \n",
      "\n",
      "\n",
      "\n",
      "Human: How do I know if this is a good investment.\n",
      "\n",
      "Assistant: It really depends on the details of your situation, and the kind of investor you are.  I’d say that the risk and potential benefits of getting into a retirement fund are, at best, highly dependent on your personal situation.  But I have some information that helps get this right: I can point you to a study that says that, on average, people can get better than average returns on how much they spend on this type of fund.  The risks of this fund are estimated to be. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_res = lambda dataset,res:[  \"\\n\\nHuman: \"+prompt + \"\\n\\nAssistant: \"+resp for prompt, \n",
    "                            resp in zip(dataset[\"train\"][\"prompt\"], dataset[\"train\"][res])]\n",
    "\n",
    "chosen_samples = get_res( dataset,'chosen')\n",
    "rejected_samples = get_res( dataset,'rejected') \n",
    "\n",
    "print(chosen_samples[2],'\\n')\n",
    "print(rejected_samples[2],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59767c46",
   "metadata": {},
   "source": [
    "From these, we create a more complete dataset, which is a dict with keys `['prompt', 'chosen', 'rejected', 'prompt_chosen', 'prompt_rejected']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "11d04521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_combined_columns(example):\n",
    "    # Combine 'prompt' with 'chosen' response, formatting it with \"Human:\" and \"Assistant:\" labels\n",
    "    example['prompt_chosen'] = \"\\n\\nHuman: \" + example[\"prompt\"] + \"\\n\\nAssistant: \" + example[\"chosen\"]\n",
    "    \n",
    "    # Combine 'prompt' with 'rejected' response, formatting it with \"Human:\" and \"Assistant:\" labels\n",
    "    example['prompt_rejected'] = \"\\n\\nHuman: \" + example[\"prompt\"] + \"\\n\\nAssistant: \" + example[\"rejected\"]\n",
    "    \n",
    "    # Return the modified example\n",
    "    return example\n",
    "\n",
    "dataset['train'] = dataset['train'].map(add_combined_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c275eb9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'How do I know if this is a good investment.',\n",
       " 'chosen': 'Answer: To determine if an investment is a good one, it is important to consider the potential risks and rewards of the investment, as well as the cost, expected rate of return, and timeline involved in the investment. Additionally, it is also important to research the company or asset in question, factoring in any additional information to determine if investing in it is a wise decision.',\n",
       " 'rejected': 'It really depends on the details of your situation, and the kind of investor you are.  I’d say that the risk and potential benefits of getting into a retirement fund are, at best, highly dependent on your personal situation.  But I have some information that helps get this right: I can point you to a study that says that, on average, people can get better than average returns on how much they spend on this type of fund.  The risks of this fund are estimated to be.',\n",
       " 'prompt_chosen': '\\n\\nHuman: How do I know if this is a good investment.\\n\\nAssistant: Answer: To determine if an investment is a good one, it is important to consider the potential risks and rewards of the investment, as well as the cost, expected rate of return, and timeline involved in the investment. Additionally, it is also important to research the company or asset in question, factoring in any additional information to determine if investing in it is a wise decision.',\n",
       " 'prompt_rejected': '\\n\\nHuman: How do I know if this is a good investment.\\n\\nAssistant: It really depends on the details of your situation, and the kind of investor you are.  I’d say that the risk and potential benefits of getting into a retirement fund are, at best, highly dependent on your personal situation.  But I have some information that helps get this right: I can point you to a study that says that, on average, people can get better than average returns on how much they spend on this type of fund.  The risks of this fund are estimated to be.'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a84b3a4",
   "metadata": {},
   "source": [
    "For filtering, we want to exclude to long sentences (where too long is > `max_length`in the section model). Moreover, we want to exclude too short sentences, because it is useful to use long and articulated sentences, with a lenght near to the one of `max_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b91f6f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_max_len= lambda samples: max([len(sample) for sample in samples])\n",
    "\n",
    "find_short = lambda dataset, max_length: [\n",
    "    i for i, (chosen, rejected) in enumerate(zip(dataset['prompt_chosen'], dataset['prompt_rejected']))\n",
    "    if len(chosen) < max_length or len(rejected) < max_length\n",
    "]\n",
    "\n",
    "max_length=1024\n",
    "subset_indices=find_short (dataset['train'], max_length)\n",
    "dataset['train'] = dataset['train'].select(subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ce580ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_str = {'chosen': [sample for sample in dataset['train'] ['prompt_chosen']], 'rejected':[sample for sample in dataset['train'] ['prompt_rejected']]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f8e364",
   "metadata": {},
   "source": [
    "Then we want to tokenize the prompt, the rejected and accepted answers to give them to the reward trainer (similarly, we to it for attention masks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "62f1e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it takes 50s\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the 'prompt_chosen' text with truncation and padding to the maximum length\n",
    "    tokenized_chosen = tokenizer(examples['prompt_chosen'], truncation = True, max_length = max_length, padding = \"max_length\")\n",
    "    \n",
    "    # Tokenize the 'prompt_rejected' text with truncation and padding to the maximum length\n",
    "    tokenized_rejected = tokenizer(examples['prompt_rejected'], truncation = True, max_length = max_length, padding = \"max_length\")\n",
    "    \n",
    "    # Return the tokenized inputs as a dictionary\n",
    "    return {\n",
    "        \"input_ids_chosen\": tokenized_chosen[\"input_ids\"],  # Token IDs for 'chosen' responses\n",
    "        \"attention_mask_chosen\": tokenized_chosen[\"attention_mask\"],  # Attention masks for 'chosen' responses\n",
    "\n",
    "        \"input_ids_rejected\": tokenized_rejected[\"input_ids\"],  # Token IDs for 'rejected' responses\n",
    "        \"attention_mask_rejected\": tokenized_rejected[\"attention_mask\"],  # Attention masks for 'rejected' responses\n",
    "    }\n",
    "\n",
    "dataset['train'] = dataset['train'].map(preprocess_function, batched = True, \n",
    "                remove_columns=['prompt',\"chosen\", \"rejected\",'prompt_chosen', 'prompt_rejected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6b1c05c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = dataset['train'].train_test_split(test_size = 0.2)\n",
    "\n",
    "# Create a DatasetDict to hold train and test splits\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': split_dataset['train'],\n",
    "    'test': split_dataset['test'],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9841b1a0",
   "metadata": {},
   "source": [
    "## Reward trainer and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc941d50",
   "metadata": {},
   "source": [
    "The `RewardTrainer` is a specialized trainer that is designed to train models with a reward signal. This is often used in reinforcement learning scenarios where the model learns to optimize for better responses. It is initialized with several parameters:\n",
    "\n",
    "- **model**: The model to be trained\n",
    "- **args**: The training arguments. Typically, an instance of `TrainingArguments`\n",
    "- **tokenizer**: The tokenizer used to process the text inputs\n",
    "- **train_dataset**: The training data set\n",
    "- **eval_dataset**: The evaluation data set\n",
    "- **peft_config**: The configuration for LoRA\n",
    "\n",
    "The `RewardTrainer` orchestrates the training process, handling tasks such as batching, optimization, evaluation, and saving model checkpoints. It is particularly useful for training models that need to learn from feedback signals, improving their ability to generate high-quality responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d4add0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"attn.c_attn\", \"attn.c_proj\"]  # Target attention layers\n",
    ")\n",
    "\n",
    "training_args = RewardConfig(\n",
    "    per_device_train_batch_size=3,\n",
    "    num_train_epochs=3,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=1.41e-5,\n",
    "    output_dir=\"./model_output3\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    #disable_dropout=True,  \n",
    "    fp16=False,   # forza esplicita\n",
    "    bf16=False,\n",
    "    no_cuda=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ac9a9503",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRewardProcessor:\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizerBase, max_length: int = 512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        # Supponendo che 'text' sia il campo nel dataset\n",
    "        return self.tokenizer(\n",
    "            examples[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "188bfd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = SimpleRewardProcessor(tokenizer=tokenizer)\n",
    "\n",
    "trainer = RewardTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_dict['train'],\n",
    "    eval_dataset=dataset_dict['test'],\n",
    "    peft_config=lora_config,\n",
    "    #processing_class=processor,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c42b5f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir=\"./model_output3\"\n",
    "\n",
    "# # Train the model\n",
    "# trainer.train()\n",
    "\n",
    "# # Save the model\n",
    "# trainer.save_model(output_dir)\n",
    "\n",
    "# # Evaluate the model\n",
    "# metrics = trainer.evaluate()\n",
    "# print(metrics)\n",
    "\n",
    "# model.config.save_pretrained(\"./backup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232415cf",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b1c03329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(20189) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-08-03 16:25:45--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/VZcK8FJ-kQ3nEJoxWGNYTQ/RetriverTrainerModel.zip\n",
      "Risoluzione di cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 198.23.119.245\n",
      "Connessione a cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|198.23.119.245|:443... connesso.\n",
      "Richiesta HTTP inviata, in attesa di risposta... 200 OK\n",
      "Lunghezza: 13238247 (13M) [application/zip]\n",
      "Salvataggio in: «RetriverTrainerModel.zip»\n",
      "\n",
      "RetriverTrainerMode 100%[===================>]  12.62M   882KB/s    in 12s     \n",
      "\n",
      "2025-08-03 16:25:58 (1.08 MB/s) - «RetriverTrainerModel.zip» salvato [13238247/13238247]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(20190) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  RetriverTrainerModel.zip\n",
      "   creating: /Users/alex/Desktop/programmazione/notebooks/My notebooks/IBM Generative AI with LLMs/extracted_model/model_output3\n",
      "  inflating: extracted_model/__MACOSX/._model_output3  \n",
      "   creating: /Users/alex/Desktop/programmazione/notebooks/My notebooks/IBM Generative AI with LLMs/extracted_model/model_output3/checkpoint-2500\n",
      "  inflating: extracted_model/__MACOSX/model_output3/._checkpoint-2500  \n",
      "  inflating: extracted_model/model_output3/adapter_model.safetensors  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._adapter_model.safetensors  \n",
      "  inflating: extracted_model/model_output3/.DS_Store  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._.DS_Store  \n",
      "  inflating: extracted_model/model_output3/tokenizer_config.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._tokenizer_config.json  \n",
      "  inflating: extracted_model/model_output3/special_tokens_map.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._special_tokens_map.json  \n",
      "  inflating: extracted_model/model_output3/config.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._config.json  \n",
      "  inflating: extracted_model/model_output3/README.md  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._README.md  \n",
      "  inflating: extracted_model/model_output3/merges.txt  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._merges.txt  \n",
      "  inflating: extracted_model/model_output3/training_args.bin  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._training_args.bin  \n",
      "  inflating: extracted_model/model_output3/adapter_config.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._adapter_config.json  \n",
      "  inflating: extracted_model/model_output3/vocab.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._vocab.json  \n",
      "   creating: /Users/alex/Desktop/programmazione/notebooks/My notebooks/IBM Generative AI with LLMs/extracted_model/model_output3/runs\n",
      "  inflating: extracted_model/__MACOSX/model_output3/._runs  \n",
      "   creating: /Users/alex/Desktop/programmazione/notebooks/My notebooks/IBM Generative AI with LLMs/extracted_model/model_output3/checkpoint-3000\n",
      "  inflating: extracted_model/__MACOSX/model_output3/._checkpoint-3000  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/adapter_model.safetensors  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._adapter_model.safetensors  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/rng_state.pth  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._rng_state.pth  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/tokenizer_config.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._tokenizer_config.json  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/special_tokens_map.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._special_tokens_map.json  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/optimizer.pt  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._optimizer.pt  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/scheduler.pt  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._scheduler.pt  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/README.md  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._README.md  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/merges.txt  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._merges.txt  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/training_args.bin  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._training_args.bin  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/adapter_config.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._adapter_config.json  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/vocab.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._vocab.json  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/trainer_state.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._trainer_state.json  \n",
      "  inflating: extracted_model/model_output3/runs/.DS_Store  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/runs/._.DS_Store  \n",
      "   creating: /Users/alex/Desktop/programmazione/notebooks/My notebooks/IBM Generative AI with LLMs/extracted_model/model_output3/runs/Jun26_13-15-27_notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps\n",
      "  inflating: extracted_model/__MACOSX/model_output3/runs/._Jun26_13-15-27_notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/adapter_model.safetensors  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._adapter_model.safetensors  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/rng_state.pth  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._rng_state.pth  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/tokenizer_config.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._tokenizer_config.json  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/special_tokens_map.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._special_tokens_map.json  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/optimizer.pt  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._optimizer.pt  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/scheduler.pt  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._scheduler.pt  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/README.md  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._README.md  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/merges.txt  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._merges.txt  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/training_args.bin  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._training_args.bin  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/adapter_config.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._adapter_config.json  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/vocab.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._vocab.json  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/trainer_state.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._trainer_state.json  \n",
      "  inflating: extracted_model/model_output3/runs/Jun26_13-15-27_notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps/events.out.tfevents.1719421727.notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps.131.1  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/runs/Jun26_13-15-27_notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps/._events.out.tfevents.1719421727.notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps.131.1  \n",
      "  inflating: extracted_model/model_output3/runs/Jun26_13-15-27_notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps/events.out.tfevents.1719407764.notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps.131.0  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/runs/Jun26_13-15-27_notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps/._events.out.tfevents.1719407764.notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps.131.0  \n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/VZcK8FJ-kQ3nEJoxWGNYTQ/RetriverTrainerModel.zip\n",
    "!unzip -o RetriverTrainerModel.zip -d extracted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1b9e554f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = GPT2ForSequenceClassification.from_pretrained(\"./extracted_model/model_output3\", num_labels = 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "62560b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_file = f\"extracted_model/model_output3/checkpoint-2500/trainer_state.json\"\n",
    "\n",
    "# Read the log file\n",
    "with open(log_file, 'r') as f:\n",
    "    logs = json.load(f)\n",
    "\n",
    "# Extract training loss values\n",
    "steps = []\n",
    "losses = []\n",
    "for log in logs[\"log_history\"]:\n",
    "    if \"loss\" in log:\n",
    "        steps.append(log[\"step\"])\n",
    "        losses.append(log[\"loss\"])\n",
    "\n",
    "# Plot the training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, losses, label=\"Training Loss\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Over Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ea6e33",
   "metadata": {},
   "source": [
    "We want to compare scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2643de31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected first\n",
      "\n",
      "\n",
      "Human: How do I know if this is a good investment.\n",
      "\n",
      "Assistant: Answer: To determine if an investment is a good one, it is important to consider the potential risks and rewards of the investment, as well as the cost, expected rate of return, and timeline involved in the investment. Additionally, it is also important to research the company or asset in question, factoring in any additional information to determine if investing in it is a wise decision. score: 8.073410987854004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nHuman: How do I know if this is a good investment.\\n\\nAssistant: Answer: To determine if an investment is a good one, it is important to consider the potential risks and rewards of the investment, as well as the cost, expected rate of return, and timeline involved in the investment. Additionally, it is also important to research the company or asset in question, factoring in any additional information to determine if investing in it is a wise decision.'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to make a prediction and get the logits\n",
    "def predict_and_get_logits(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Perform the forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Extract the logits from the outputs\n",
    "    logits = outputs.logits.squeeze().item()  # Assuming binary classification and batch size of 1\n",
    "    \n",
    "    return logits\n",
    "\n",
    "def compare_texts(text1, text2):\n",
    "    logit1 = predict_and_get_logits(text1)\n",
    "    logit2 = predict_and_get_logits(text2)\n",
    "\n",
    "    if logit1 > logit2:\n",
    "        print(\"selected first\")\n",
    "        print(text1, f\"score: {logit1}\")\n",
    "\n",
    "        return text1\n",
    "    else:\n",
    "        print(\"selected second\")\n",
    "        print(text2,  f\"score: {logit2}\")\n",
    "\n",
    "        return text2\n",
    "\n",
    "compare_texts(train_str['chosen'][2],train_str['rejected'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f83d0b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: I was wondering if you could walk me through the process of setting up a hydroponic garden for herbs.\n",
      "\n",
      "Assistant: Sure! The process for setting up a hydroponic garden for herbs is relatively simple. First, you'll want to choose a space where you will set up your hydroponic system. You'll need to make sure the space is well-lit and has access to electricity and an adequate water supply. Next, you'll need to choose the type of hydroponic system you want to use. There are several types of hydroponic systems, so you'll need to decide which best suits your needs. Once you've chosen a system, you'll need to gather the supplies you'll need to assemble it. This includes things like pumps, growing trays, grow lights, and nutrients. Once you've assembled the system, you'll need to add your choice of herbs to the system. Lastly, you'll need to monitor and adjust the system as needed to ensure your herbs are getting the correct amount of light, water, and nutrients.\n",
      "selected first\n",
      "\n",
      "\n",
      "Human: I was wondering if you could walk me through the process of setting up a hydroponic garden for herbs.\n",
      "\n",
      "Assistant: Sure! The process for setting up a hydroponic garden for herbs is relatively simple. First, you'll want to choose a space where you will set up your hydroponic system. You'll need to make sure the space is well-lit and has access to electricity and an adequate water supply. Next, you'll need to choose the type of hydroponic system you want to use. There are several types of hydroponic systems, so you'll need to decide which best suits your needs. Once you've chosen a system, you'll need to gather the supplies you'll need to assemble it. This includes things like pumps, growing trays, grow lights, and nutrients. Once you've assembled the system, you'll need to add your choice of herbs to the system. Lastly, you'll need to monitor and adjust the system as needed to ensure your herbs are getting the correct amount of light, water, and nutrients. score: 7.60854959487915\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: What type of wine goes best with steak.\n",
      "\n",
      "Assistant: The best type of wine to pair with steak depends largely on the cut and preparation of the steak. Generally, a full-bodied red wine like Cabernet Sauvignon or Syrah is a good choice, as its bold flavors can stand up to the rich flavors of the steak. Other good options for pairing with steak include Bordeaux, merlot, zinfandel, and malbec. A lighter red like pinot noir can also be a great choice for lighter cuts of steak. For white wines, a buttery chardonnay or a bold sauvignon blanc can be great choices. A sparkling wine, such as Prosecco, can also go well with steak.\n",
      "selected first\n",
      "\n",
      "\n",
      "Human: What type of wine goes best with steak.\n",
      "\n",
      "Assistant: The best type of wine to pair with steak depends largely on the cut and preparation of the steak. Generally, a full-bodied red wine like Cabernet Sauvignon or Syrah is a good choice, as its bold flavors can stand up to the rich flavors of the steak. Other good options for pairing with steak include Bordeaux, merlot, zinfandel, and malbec. A lighter red like pinot noir can also be a great choice for lighter cuts of steak. For white wines, a buttery chardonnay or a bold sauvignon blanc can be great choices. A sparkling wine, such as Prosecco, can also go well with steak. score: 9.168907165527344\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: How do I know if this is a good investment.\n",
      "\n",
      "Assistant: Answer: To determine if an investment is a good one, it is important to consider the potential risks and rewards of the investment, as well as the cost, expected rate of return, and timeline involved in the investment. Additionally, it is also important to research the company or asset in question, factoring in any additional information to determine if investing in it is a wise decision.\n",
      "selected first\n",
      "\n",
      "\n",
      "Human: How do I know if this is a good investment.\n",
      "\n",
      "Assistant: Answer: To determine if an investment is a good one, it is important to consider the potential risks and rewards of the investment, as well as the cost, expected rate of return, and timeline involved in the investment. Additionally, it is also important to research the company or asset in question, factoring in any additional information to determine if investing in it is a wise decision. score: 8.320837020874023\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: Please provide me with some financial advice.\n",
      "\n",
      "Assistant: Some financial advice is to always pay yourself first. Make sure to allocate a percentage of your salary to long-term savings and investments each month. Develop a budget and stick to it, and make sure that you save for unexpected expenses. Monitor your spending to make sure you are not overspending, and look for ways to save money on everyday costs. Plan for retirement early and consider speaking with a certified financial planner for more personalized advice.\n",
      "selected first\n",
      "\n",
      "\n",
      "Human: Please provide me with some financial advice.\n",
      "\n",
      "Assistant: Some financial advice is to always pay yourself first. Make sure to allocate a percentage of your salary to long-term savings and investments each month. Develop a budget and stick to it, and make sure that you save for unexpected expenses. Monitor your spending to make sure you are not overspending, and look for ways to save money on everyday costs. Plan for retirement early and consider speaking with a certified financial planner for more personalized advice. score: 9.331151008605957\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: What kind of safety devices do I need to install in my house.\n",
      "\n",
      "Assistant: The type of safety devices you should install in your home depend on your specific needs, but some of the most common safety devices include smoke and carbon monoxide detectors, security systems, fire extinguishers, and window locks. Additionally, you may want to look into motion-activated lights, home surveillance systems, window and door alarms, or other safety-specific items.\n",
      "selected first\n",
      "\n",
      "\n",
      "Human: What kind of safety devices do I need to install in my house.\n",
      "\n",
      "Assistant: The type of safety devices you should install in your home depend on your specific needs, but some of the most common safety devices include smoke and carbon monoxide detectors, security systems, fire extinguishers, and window locks. Additionally, you may want to look into motion-activated lights, home surveillance systems, window and door alarms, or other safety-specific items. score: 8.629776954650879\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: How do I interpret the results of my blood test.\n",
      "\n",
      "Assistant: To interpret the results of your blood test, it is important to consult with your doctor or healthcare provider. They can help explain the significance of your results and provide information on lifestyle changes you may need to make to improve your health. Additionally, they can provide further medical testing or treatments if necessary.\n",
      "selected first\n",
      "\n",
      "\n",
      "Human: How do I interpret the results of my blood test.\n",
      "\n",
      "Assistant: To interpret the results of your blood test, it is important to consult with your doctor or healthcare provider. They can help explain the significance of your results and provide information on lifestyle changes you may need to make to improve your health. Additionally, they can provide further medical testing or treatments if necessary. score: 8.790009498596191\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: I'm having trouble finding the perfect job. What resources can help me.\n",
      "\n",
      "Assistant: Start by making a list of your interests and skills, then use job search websites such as Indeed or Glassdoor to search for openings that match your criteria. You can also use professional networking sites such as LinkedIn to find positions that are a good fit for you. Additionally, you can talk to friends and family members who may be able to offer advice and connect you with potential jobs. Lastly, consider attending job fairs in your area to explore different employers and opportunities.\n",
      "selected first\n",
      "\n",
      "\n",
      "Human: I'm having trouble finding the perfect job. What resources can help me.\n",
      "\n",
      "Assistant: Start by making a list of your interests and skills, then use job search websites such as Indeed or Glassdoor to search for openings that match your criteria. You can also use professional networking sites such as LinkedIn to find positions that are a good fit for you. Additionally, you can talk to friends and family members who may be able to offer advice and connect you with potential jobs. Lastly, consider attending job fairs in your area to explore different employers and opportunities. score: 10.180100440979004\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: What does a roux look like.\n",
      "\n",
      "Assistant: A roux is a mixture of fat, such as butter or oil, and flour that is cooked together until it is a smooth paste and used as a base for sauces and soups. It is usually a yellowish or tan color and can range from a paste-like consistency to a thick lumpy paste.\n",
      "selected first\n",
      "\n",
      "\n",
      "Human: What does a roux look like.\n",
      "\n",
      "Assistant: A roux is a mixture of fat, such as butter or oil, and flour that is cooked together until it is a smooth paste and used as a base for sauces and soups. It is usually a yellowish or tan color and can range from a paste-like consistency to a thick lumpy paste. score: 3.8470494747161865\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: How to make money online.\n",
      "\n",
      "Assistant: One way to make money online is to start a business offering services or selling products online. This could include setting up an online store, selling products on a marketplace website, offering freelance services such as writing, web design, and virtual assistance, creating digital products such as an ebook or online course, and becoming an affiliate for someone else’s products or services. Additionally, you could start freelancing by using online sites such as Upwork, Fiverr, and Freelancer. You can also look into generating passive income streams by investing in stocks, real estate, and mutual funds or finding ways to monetize your blog or YouTube channel.\n",
      "selected first\n",
      "\n",
      "\n",
      "Human: How to make money online.\n",
      "\n",
      "Assistant: One way to make money online is to start a business offering services or selling products online. This could include setting up an online store, selling products on a marketplace website, offering freelance services such as writing, web design, and virtual assistance, creating digital products such as an ebook or online course, and becoming an affiliate for someone else’s products or services. Additionally, you could start freelancing by using online sites such as Upwork, Fiverr, and Freelancer. You can also look into generating passive income streams by investing in stocks, real estate, and mutual funds or finding ways to monetize your blog or YouTube channel. score: 5.970852375030518\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: What are some job options for engineering majors.\n",
      "\n",
      "Assistant: Some job options for engineering majors include aerospace engineer, civil engineer, computer engineer, electrical engineer, mechanical engineer, software engineer, chemical engineer, biomedical engineer, and environmental engineer.\n",
      "selected first\n",
      "\n",
      "\n",
      "Human: What are some job options for engineering majors.\n",
      "\n",
      "Assistant: Some job options for engineering majors include aerospace engineer, civil engineer, computer engineer, electrical engineer, mechanical engineer, software engineer, chemical engineer, biomedical engineer, and environmental engineer. score: 4.4615864753723145\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Define the number of samples to evaluate\n",
    "N = 10\n",
    "\n",
    "# Initialize a counter for correct selections\n",
    "correct_selections = 0\n",
    "\n",
    "# Iterate over the first N pairs of chosen and rejected responses\n",
    "for chosen, rejected in zip(train_str['chosen'][0:N], train_str['rejected'][0:N]):\n",
    "    # Print the chosen response for reference\n",
    "    print(\"Chosen Response:\\n\", chosen)\n",
    "    \n",
    "    # Use the compare_texts function to determine which response is better\n",
    "    selected_text = compare_texts(chosen, rejected)\n",
    "    \n",
    "    # Check if the selected text is the chosen response\n",
    "    if selected_text == chosen:\n",
    "        correct_selections += 1\n",
    "\n",
    "# Calculate the accuracy as the ratio of correct selections to the total number of samples\n",
    "accuracy = correct_selections / N\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74007f77",
   "metadata": {},
   "source": [
    "# 3) PPO: not done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a3d42",
   "metadata": {},
   "source": [
    "# 4) DPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e34d14",
   "metadata": {},
   "source": [
    "## Models and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6c0e889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GPT-2 model, to be fine-tuned using DPO\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load a reference model \n",
    "model_ref = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load the GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Set the pad token to the end-of-sequence token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# Set the padding side to \"right\" to fix the overflow issue with FP16 training\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# Disable the use of the cache during the model's forward pass\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad7fdc",
   "metadata": {},
   "source": [
    "## Dataset and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e2da5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"BarraHome/ultrafeedback_binarized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c65f70c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train_prefs\"][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28624c9",
   "metadata": {},
   "source": [
    "Now, put the data set in the format that the DPO trainer accepts, which is:\n",
    "\n",
    "| Chosen | Rejected | Prompt |\n",
    "| --- | --- | --- |\n",
    " | Developing a daily habit of drawing can be challenging <br>but with consistent practice, and a few tips. | One way to develop a habit of drawing daily is <br>to allocate a specific time interval for drawing. | How can I develop a habit of drawing daily?|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b76f8908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(20213) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20214) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20215) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20216) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20217) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20218) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20219) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20220) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49dc011e70346719ecf85307d5cb485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(20221) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20222) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20223) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20224) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20225) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20226) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20227) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20228) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20229) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4e6dffbd1740f9a9ce1a14b0a31d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(20230) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20231) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20232) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20233) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20234) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20235) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20236) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20237) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20238) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df338f473c0348b59cd2253f215d6572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(20239) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20240) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20241) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20242) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20243) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20244) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20245) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20246) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20247) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0a4546a3264df983e858bb902c1295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(20248) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20249) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20250) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20251) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20252) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20253) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20254) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20255) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20256) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5046995f1ea40838a2567aaa0df18ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(20257) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20258) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20259) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20260) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20261) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20262) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20263) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20264) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(20265) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ea3e7b1bc8475cb11e42b3f6730f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(20266) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "for key in ds:\n",
    "    #cnt = round(ds[key].__len__()*0.05)\n",
    "    cnt=50\n",
    "    ds[key] = ds[key].select(range(cnt))\n",
    "\n",
    "# Define a function to process the data\n",
    "def process(row):\n",
    "    # delete unwanted columns\n",
    "    del row[\"prompt_id\"]\n",
    "    del row[\"messages\"]\n",
    "    del row[\"score_chosen\"]\n",
    "    del row[\"score_rejected\"]\n",
    "    # retrieve the actual response text\n",
    "    row[\"chosen\"] = row[\"chosen\"][-1][\"content\"]\n",
    "    row[\"rejected\"] = row[\"rejected\"][-1][\"content\"]\n",
    "\n",
    "    return row\n",
    "\n",
    "# Apply the data processing function to the dataset\n",
    "ds = ds.map(\n",
    "    process,\n",
    "    num_proc=multiprocessing.cpu_count(),\n",
    "    load_from_cache_file=False,\n",
    ")\n",
    "\n",
    "# Split the dataset into training and evaluation sets\n",
    "train_dataset = ds['train_prefs']\n",
    "eval_dataset = ds['test_prefs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f0d35524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'how can i develop a habit of drawing daily',\n",
       " 'chosen': \"Developing a daily habit of drawing can be challenging but with consistent practice and a few tips, it can become an enjoyable and rewarding part of your daily routine. Here are some strategies to help you develop the habit of drawing daily:\\n\\n1. Set a specific time: Allocate a specific time of the day to draw. It could be in the morning, afternoon, or evening. Make drawing a part of your daily routine.\\n2. Set a specific duration: Determine the amount of time you want to spend on drawing each day. It can be as little as 10 minutes or as long as an hour. Be consistent with the duration to help build the habit.\\n3. Start small and simple: Don't try to create a masterpiece every day, start with simple and easy-to-do sketches. Focus on improving your skills gradually.\\n4. Use a variety of tools and mediums: Experiment with different tools like pencils, pens, markers, and different mediums like paper, canvas, or digital apps to keep your drawing practice interesting and engaging.\\n5. Take breaks and rest: Taking breaks and resting after some time of drawing can help you avoid burnout and stay motivated.\\n6. Challenge yourself: Set challenges like drawing objects from memory or a specific subject to improve your skills and keep your drawing practice interesting.\\n7. Track your progress: Keep a record of your daily drawing practice and track your progress. This can be a source of motivation and help you see how far you've come.\\n\\nRemember, developing a habit takes time and patience. Stay consistent with your drawing practice, be flexible and open to trying new things, and with time, you'll develop a habit of daily drawing that brings you joy and satisfaction.\",\n",
       " 'rejected': \"One way to develop a habit of drawing daily is to allocate a specific time interval for drawing each day, whether it's early in the morning or before going to bed at night. You can also find inspiration or motivation to draw by joining drawing communities, following artists on social media, or going out into nature and sketching what you see. Additionally, practicing drawing every day can help you improve your skills over time.\"}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8c0235",
   "metadata": {},
   "source": [
    "## DPO (with also LoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "06d6453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "        # The rank of the low-rank adaptation weights\n",
    "        r=4,\n",
    "        # The target modules to apply the low-rank adaptation to\n",
    "        target_modules=['c_proj','c_attn'],\n",
    "        # The task type for the low-rank adaptation\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        # The scaling factor for the low-rank adaptation weights\n",
    "        lora_alpha=8,\n",
    "        # The dropout probability for the low-rank adaptation weights\n",
    "        lora_dropout=0.1,\n",
    "        # The bias mode for the low-rank adaptation\n",
    "        bias=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "55b84385",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = DPOConfig(\n",
    "    # The beta parameter for the DPO loss function\n",
    "    #beta is the temperature parameter for the DPO loss, typically something in the range of 0.1 to 0.5 . \n",
    "    beta=0.1,\n",
    "    # The output directory for the training\n",
    "    output_dir=\"dpo\",\n",
    "    # The number of training epochs\n",
    "    num_train_epochs=5,\n",
    "    # The batch size per device during training\n",
    "    per_device_train_batch_size=1,\n",
    "    # The batch size per device during evaluation\n",
    "    per_device_eval_batch_size=1,\n",
    "    # Whether to remove unused columns from the dataset\n",
    "    remove_unused_columns=False,\n",
    "    # The number of steps between logging training progress\n",
    "    logging_steps=10,\n",
    "    # The number of gradient accumulation steps\n",
    "    gradient_accumulation_steps=1,\n",
    "    # The learning rate for the optimization\n",
    "    learning_rate=1e-4,\n",
    "    # The evaluation strategy (e.g., after each step or epoch)\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    # The number of warmup steps for the learning rate scheduler\n",
    "    warmup_steps=2,\n",
    "    # Whether to use 16-bit (float16) precision\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    # The number of steps between saving checkpoints\n",
    "    save_steps=500,\n",
    "    # The maximum number of checkpoints to keep\n",
    "    #save_total_limit=2,\n",
    "    # The reporting backend to use (set to 'none' to disable, you can also report to wandb or tensorboard)\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a3b7048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Create a DPO trainer\n",
    "# This trainer will handle the fine-tuning of the model using the DPO technique\n",
    "trainer = DPOTrainer(\n",
    "        # The model to be fine-tuned\n",
    "        model = model,\n",
    "        tokenizer = tokenizer,\n",
    "        # The reference model (not used in this case because LoRA has been used)\n",
    "        ref_model=None,\n",
    "        # The DPO training configuration\n",
    "        args=training_args,\n",
    "        # The beta parameter for the DPO loss function\n",
    "       \n",
    "        # The training dataset\n",
    "        train_dataset=train_dataset,\n",
    "        # The evaluation dataset\n",
    "        eval_dataset=eval_dataset,\n",
    "        # The tokenizer for the model\n",
    "        #tokenizer=tokenizer,\n",
    "        # The PEFT (Parallel Efficient Finetuning) configuration\n",
    "        peft_config=lora_config,\n",
    "        # The maximum prompt length\n",
    "        #max_prompt_length=512,\n",
    "        # The maximum sequence length\n",
    "        #max_length=512,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6fdcff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2bfd04",
   "metadata": {},
   "source": [
    "## Evaluate and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "00c0d82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted: ['DPO', 'DPO/adapter_config.json', 'DPO/tokenizer_config.json', 'DPO/merges.txt', 'DPO/adapter_model.safetensors', 'DPO/special_tokens_map.json', 'DPO/training_args.bin', 'DPO/README.md', 'DPO/vocab.json']\n"
     ]
    }
   ],
   "source": [
    "# Define the URL and the filename\n",
    "url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/YIDeT3qihEpWChdXN_RmTg/DPO-tar.gz'\n",
    "filename = './DPO.tar'\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "\n",
    "# Save the file locally\n",
    "with open(filename, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Extract the tar file\n",
    "if tarfile.is_tarfile(filename):\n",
    "    with tarfile.open(filename, 'r') as tar:\n",
    "        tar.extractall()\n",
    "        print(\"Files extracted:\", tar.getnames())\n",
    "else:\n",
    "    print(\"The adownloaded file is not a tar file.\")\n",
    "\n",
    "dpo_model = AutoModelForCausalLM.from_pretrained('./DPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4f5557f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPO response:\t Is a higher octane gasoline better for your car?\n",
      "\n",
      "The answer is yes. The higher octane gasoline is better for your car.\n",
      "\n",
      "The higher octane gasoline\n",
      "\n",
      "GPT2 response:\t Is a higher octane gasoline better for your car?\n",
      "\n",
      "The answer is yes. The higher octane gasoline is more efficient and more fuel efficient.\n",
      "\n",
      "The higher oct\n"
     ]
    }
   ],
   "source": [
    "# Define the generation configuration for the DPO model\n",
    "# This sets the parameters for text generation\n",
    "generation_config = GenerationConfig(\n",
    "        # Use sampling to generate diverse text\n",
    "        do_sample=True,\n",
    "        # Top-k sampling parameter\n",
    "        top_k=1,\n",
    "        # Temperature parameter to control the randomness of the generated text\n",
    "        temperature=0.1,\n",
    "        # Maximum number of new tokens to generate\n",
    "        max_new_tokens=25,\n",
    "        # Use the end-of-sequence token as the padding token\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# Define the input prompt for text generation\n",
    "PROMPT = \"Is a higher octane gasoline better for your car?\"\n",
    "# Encode the prompt using the tokenizer\n",
    "inputs = tokenizer(PROMPT, return_tensors='pt')\n",
    "\n",
    "# Generate text using the DPO model\n",
    "outputs = dpo_model.generate(**inputs, generation_config=generation_config)\n",
    "# Decode the generated text and print it\n",
    "print(\"DPO response:\\t\",tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "\n",
    "# Load the pre-trained GPT-2 model\n",
    "gpt2_model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "# Generate text using the GPT-2 model\n",
    "outputs = gpt2_model.generate(**inputs, generation_config=generation_config)\n",
    "# Decode the generated text and print it\n",
    "print(\"\\nGPT2 response:\\t\",tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Trans_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
